# ğŸš€ Hybrid Memory System

> GPU-accelerated vector search with multi-vector classification for intelligent memory retrieval

[![Performance](https://img.shields.io/badge/Insert-169ms-green)](https://github.com)
[![Search](https://img.shields.io/badge/Search-287ms-green)](https://github.com)
[![Recall](https://img.shields.io/badge/Recall-100%25-brightgreen)](https://github.com)
[![Cost](https://img.shields.io/badge/API_Cost-FREE-blue)](https://github.com)

## ğŸ“‹ Overview

A production-ready memory system that combines:
- **Qdrant** for fast vector search
- **GPU-accelerated classification** using Qwen2.5-0.5B
- **Multi-vector search** for superior recall
- **Async architecture** for instant responses
- **Zero API costs** with local embeddings

### Performance vs Mem0

| Metric | Mem0 | Hybrid System | Improvement |
|--------|------|---------------|-------------|
| **Insert Latency** | 682ms | **169ms** | **4x faster** |
| **Search Latency** | 1145ms | **287ms** | **4x faster** |
| **Precision** | 100% | **100%** | Same |
| **Recall** | 80% | **100%** | **+25%** |
| **API Cost** | $$$ | **FREE** | **100% savings** |

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     CLIENT APPLICATION                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Qdrant Serviceâ”‚  (Port 8765)
        â”‚   (t3.medium)  â”‚
        â”‚                â”‚
        â”‚  - Fast Insert â”‚  â† Heuristics (50ms)
        â”‚  - Embeddings  â”‚  â† all-MiniLM-L6-v2
        â”‚  - Search      â”‚  â† Multi-vector ANN
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ (async background)
                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Classifier    â”‚  (Port 8766)
        â”‚  (g4dn.xlarge) â”‚
        â”‚                â”‚
        â”‚  - Qwen2.5-0.5Bâ”‚  â† GPU inference
        â”‚  - NVIDIA T4   â”‚  â† 15-20x faster
        â”‚  - Batch API   â”‚  â† Efficient
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âœ¨ Features

- âœ… **Instant Inserts** - Returns in ~169ms with heuristic classifiers
- âœ… **Async GPU Improvement** - Background LLM classification
- âœ… **Multi-Vector Search** - Search across text + semantic classifiers
- âœ… **100% Recall** - Find all relevant memories
- âœ… **Local Embeddings** - No API costs (all-MiniLM-L6-v2)
- âœ… **GPU Acceleration** - 15-20x faster classification
- âœ… **Batch Processing** - Efficient bulk operations
- âœ… **Score Thresholding** - Filter low-quality results

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- Node.js 16+ (for tests)
- AWS CLI configured (for deployment)
- SSH key pair for AWS

### 1. Local Development

```bash
# Clone the repository
git clone <repo-url>
cd hybrid-memory-system

# Install Python dependencies
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# Install Node dependencies (for tests)
npm install

# Start Qdrant service (CPU mode)
python src/qdrant_service.py

# In another terminal, start classifier service
python src/classifier_service.py
```

### 2. AWS Deployment

```bash
# Deploy Qdrant service (t3.medium)
./deploy-hybrid-memory.sh t3.medium

# Deploy GPU classifier (g4dn.xlarge)
./deploy-classifier-gpu.sh

# Connect services (update Qdrant with classifier URL)
source classifier-gpu-instance.env
ssh -i ~/Downloads/new-conversation-key.pem ubuntu@<QDRANT_IP> \
  "echo 'CLASSIFIER_SERVICE_URL=http://$CLASSIFIER_IP:8766' >> ~/hybrid-memory/.env"
```

### 3. Test the System

```bash
# Run comprehensive comparison test
npx ts-node test-final-comparison.ts

# Test classifier quality
npx ts-node test-classifier-quality.ts

# Test batch performance
npx ts-node test-batch-fix.ts
```

## ğŸ“š Documentation

- [**Quickstart Guide**](QUICKSTART.md) - Get started in 5 minutes
- [**Architecture**](SEPARATED_ARCHITECTURE.md) - System design details
- [**Production Config**](PRODUCTION_CONFIG.md) - Deployment guide
- [**Test Suite**](TEST_SUITE.md) - How to run tests

## ğŸ§ª API Usage

### Add Memory

```typescript
const response = await axios.post('http://localhost:8765/add_memory', {
  user_id: 'user123',
  text: 'I have a severe peanut allergy',
  topic: 'food',
  type: 'stable'
});

// Response: { status: 'success', classifiers: [...], async_improvement: true }
```

### Search Memories

```typescript
const response = await axios.post('http://localhost:8765/search', {
  user_id: 'user123',
  context: 'dietary restrictions',
  domain: 'places',
  limit: 10,
  use_classifiers: true,
  score_threshold: 0.27
});

// Response: { memories: [...] }
```

### Health Check

```bash
curl http://localhost:8765/health
# { "status": "ok", "classifier_service": "connected", ... }
```

## ğŸ“Š Test Results

### Comprehensive Comparison (Mem0 vs Hybrid)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Metric              â”‚ Mem0         â”‚ Qdrant (GPU) â”‚ Winner       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Insert Latency      â”‚ 682ms        â”‚ 169ms        â”‚ Qdrant âœ“     â”‚
â”‚ Search Latency      â”‚ 1145ms       â”‚ 287ms        â”‚ Qdrant âœ“     â”‚
â”‚ Precision           â”‚ 100.0%       â”‚ 100.0%       â”‚ Tie          â”‚
â”‚ Recall              â”‚ 80.0%        â”‚ 100.0%       â”‚ Qdrant âœ“     â”‚
â”‚ API Cost            â”‚ $$$          â”‚ FREE         â”‚ Qdrant âœ“     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ’° Cost Analysis

### AWS Costs

| Component | Instance | Cost/hr | Monthly (24/7) |
|-----------|----------|---------|----------------|
| Qdrant Service | t3.medium | $0.04 | $30 |
| Classifier (on-demand) | g4dn.xlarge | $0.53 | $380 |
| **Total (always-on)** | | **$0.57** | **$410** |
| **Total (smart usage)** | | **$0.04-0.10** | **$30-70** |

**Optimization**: Run classifier only when needed, use heuristics for real-time inserts.

### vs Mem0 Costs

- **Mem0**: API calls for every search + embedding + storage
- **Hybrid**: Zero API costs (local embeddings + GPU)
- **Savings**: 100% on API costs

## ğŸ”§ Configuration

### Environment Variables

```bash
# Qdrant Service
USE_CLASSIFIER_SERVICE=true
CLASSIFIER_SERVICE_URL=http://localhost:8766

# Optional
MEM0_API_KEY=m0-xxx...  # For comparison tests
```

### Performance Tuning

```python
# qdrant_service.py
score_threshold = 0.27  # Adjust for precision/recall tradeoff

# classifier_service.py
max_new_tokens = 20     # Reduce for faster inference
temperature = 0.05      # Lower for more deterministic output
```

## ğŸ¯ Use Cases

- **Conversational AI** - Remember user preferences across sessions
- **Recommendation Systems** - Personalized suggestions based on history
- **Customer Support** - Recall past interactions and preferences
- **Personal Assistants** - Context-aware responses
- **RAG Applications** - Enhanced retrieval with semantic understanding

## ğŸ¤ Contributing

Contributions welcome! Please read our contributing guidelines first.

## ğŸ“ License

MIT License - see LICENSE file for details

## ğŸ™ Acknowledgments

- **Qdrant** - Vector database
- **Sentence Transformers** - Embedding models
- **Qwen** - Classification LLM
- **Mem0** - Inspiration and comparison baseline

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/your-repo/issues)
- **Discussions**: [GitHub Discussions](https://github.com/your-repo/discussions)
- **Email**: support@example.com

---

**Built with â¤ï¸ for production-ready AI memory systems**
